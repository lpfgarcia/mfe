% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/infotheo.R
\name{mf.infotheo}
\alias{mf.infotheo}
\alias{mf.infotheo.default}
\alias{mf.infotheo.formula}
\title{Information-theoretic meta-features}
\usage{
mf.infotheo(...)

\method{mf.infotheo}{default}(x, y, features = "all", summary = c("mean",
  "sd"), transform = TRUE, ...)

\method{mf.infotheo}{formula}(formula, data, features = "all",
  summary = c("mean", "sd"), transform = TRUE, ...)
}
\arguments{
\item{...}{Further arguments passed to the summarization functions.}

\item{x}{A data.frame contained only the input attributes.}

\item{y}{A factor response vector with one label for each row/component of x.}

\item{features}{A list of features names or \code{"all"} to include all them.
The supported values are described in the details section. (Default: 
\code{"all"})}

\item{summary}{A list of summarization functions or empty for all values. See
\link{post.processing} method to more information. (Default: 
\code{c("mean", "sd")})}

\item{transform}{A logical value indicading if the numeric attributes should 
be transformed. If \code{FALSE} they will be ignored. (Default: 
\code{TRUE})}

\item{formula}{A formula to define the class column.}

\item{data}{A data.frame dataset contained the input attributes and class
The details section describes the valid values for this group.}
}
\value{
A list named by the requested meta-features.
}
\description{
Information-theoretic meta-features are particularly appropriate to describe
discrete (categorical) attributes, but they also fit continuous ones so a
discretization is required.
}
\details{
The following features are allowed for this method:
 \describe{
   \item{"attrConc"}{Attributes concentration. It is the Goodman and 
     Kruskal's tau measure otherwise known as the concentration coefficient
     computed for each pair of attributes (multi-valued).}
   \item{"attrEnt"}{Attributes entropy, a measure of randomness of each 
     attributes in the dataset (multi-valued).}
   \item{"classConc"}{Class concentration, similar to "attrConc", however, it
     is computed for each attribute and the class (multi-valued).}
   \item{"classEnt"}{Class entropy, which describes how much information is 
     necessary to specify the class in the dataset.}
   \item{"eqNumAttr"}{Equivalent number of attributes, which represents the 
     number of attributes suitable to optimally solve the classification task 
     using the dataset.}
   \item{"jointEnt"}{Joint entropy, which represents the total entropy of 
     each attribute and the class (multi-valued).}
   \item{"mutInf"}{Mutual information, that is the common information shared
     between each attribute and the class in the dataset (multi-valued).}
   \item{"normAttrEnt"}{Normalized attribute entropy, a normalized version of
     "attrEnt" (multi-valued).}
   \item{"normClassEnt"}{Normalized class entropy, a normalized version of
     "classEnt".}
   \item{"nsRatio"}{Noise ratio, which describes the amount of irrelevant 
     information contained in the dataset.}
 }
 This method uses the unsupervized data discretization procedure provided by
 \link[infotheo]{discretize} function, where the default values are used when 
 \code{transform=TRUE}.
}
\examples{
## Extract all metafeatures
mf.infotheo(Species ~ ., iris)

## Extract some metafeatures
mf.infotheo(iris[1:4], iris[5], c("classEnt", "jointEnt"))

## Extract all meta-features without summarize the results
mf.infotheo(Species ~ ., iris, summary=c())

## Use another summarization functions
mf.infotheo(Species ~ ., iris, summary=c("min", "median", "max"))

## Do not transform the data (using only categorical attributes)
mf.infotheo(Species ~ ., iris, transform=FALSE)
}
\references{
Michie, E. D., Spiegelhalter, D. J., & Taylor, C. C. (1994).
   Machine Learning , Neural and Statistical Classification.
   Technometrics, 37(4), 459.

 Kalousis, A., & Hilario, M. (2001). MODEL SELECTION VIA META-LEARNING: A
   COMPARATIVE STUDY. International Journal on Artificial Intelligence Tools,
   10(4), 525-554.

 Castiello, C., Castellano, G., & Fanelli, A. M. (2005). Meta-data:
   Characterization of Input Features for Meta-learning. In Proceedings of
   the 2nd International Conference on Modeling Decisions for Artificial
   Intelligence (Vol. 3558, pp. 457-468).
}
\seealso{
Other meta-features: \code{\link{mf.discriminant}},
  \code{\link{mf.general}}, \code{\link{mf.landmarking}},
  \code{\link{mf.model.based}},
  \code{\link{mf.statistical}}
}
